{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349d9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1867943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content(file):\n",
    "    with gzip.open(file, \"rb\") as f:\n",
    "        data = f.readlines()\n",
    "        data = [d.decode() for d in data]\n",
    "        data = \"\".join(data)\n",
    "    bs_data = bs(data, \"lxml\")\n",
    "    sentences = bs_data.find_all(\"se\")\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97983b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file, content_arr, idx):\n",
    "    sentences = make_content(file)\n",
    "    for _, sent in enumerate(sentences):\n",
    "        sent_arr = []\n",
    "        sent_arr.append(str(idx))\n",
    "        lex_sent = []\n",
    "        full_sent = []\n",
    "        for word in sent.find_all('w'):\n",
    "            ana = word.find('ana')\n",
    "            lemma = ana['lex']\n",
    "            try:\n",
    "                gram = ana['gr'].split(',')[0]\n",
    "                result = lemma + '_' + gram\n",
    "            except KeyError:\n",
    "                print(word)\n",
    "                result = lemma\n",
    "            lex_sent.append(result)\n",
    "        lex_str = ' '.join(lex_sent)\n",
    "        sent_arr.append(lex_str)        \n",
    "        full_sent = sent.text.strip().replace(\"\\n\", \" \")\n",
    "        sent_arr.append(full_sent)\n",
    "        content_arr.append(sent_arr)\n",
    "        idx += 1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c66885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gzip(file, root):\n",
    "    in_path =  root + '\\\\' + file\n",
    "    out_path = root[:32] + '_gzip' + root[32:]\n",
    "    try:\n",
    "        os.makedirs(fr'{out_path}')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    with open(in_path, 'rb') as f_in, gzip.open(out_path + '\\\\' + file + '.gz', 'wb') as f_out:\n",
    "        f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37984b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file, root):\n",
    "    in_path = root + '\\\\' + file\n",
    "    out_path = root[:32] + '_no_markup' + root[32:]\n",
    "    try:\n",
    "        os.makedirs(fr'{out_path}')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    with open(in_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    bs_data = BeautifulSoup(data, \"xml\")\n",
    "    sentences = bs_data.find_all(\"se\")\n",
    "    with open(out_path + '\\\\' + file[:-3] + 'txt', \"w\", encoding=\"utf-8\") as f:\n",
    "        my_text = \"\"\n",
    "        for sentence in sentences:\n",
    "            for w in sentence.find_all(\"w\"):\n",
    "                my_text += process_word(w)\n",
    "            my_text += \"\\n\"\n",
    "        f.write(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa4138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "idx = 0\n",
    "content_arr = []\n",
    "for root, dirs, files in tqdm(os.walk(r\"E:/DATA/nkrya_full_source_merged_gzip/\")):\n",
    "    for file in tqdm(files):\n",
    "        if not file.startswith(\".\") and file.endswith(\"xml.gz\"):\n",
    "            in_path = root + '\\\\' + file\n",
    "#             write_gzip(file, root) # archive files (gzip)\n",
    "#             process_file(file, root) # write to word_LEMMA format\n",
    "            idx = get_data(in_path, content_arr, idx)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c72b9b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(content_arr, columns = ['ID','LEMMAS', 'RAW'])\n",
    "df.to_csv(\"corpus_bigger.csv.gz\", encoding = 'utf-8', index = False, compression=\"gzip\", line_terminator=\"\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016abc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a453c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
